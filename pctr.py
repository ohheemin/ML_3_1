#!/usr/bin/env python3
# -*-coding:utf-8-*-

import numpy as np

""" relu와 sigmoid 정의, 변수는 맨 밑에서 input으로 들어감 """

#===============================================================================================================

def relu(x):
    return np.maximum(0, x)

#===============================================================================================================

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

#===============================================================================================================

def init_network():
    network = {}


    network['W1'] = np.array([[0.3, 0.2, 0.1], [0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
    network['b1'] = np.zeros(3)  


    network['W2'] = np.array([[0.1, 0.2], [0.1, 0.3], [0.2, 0.4], [0.3, 0.5]])
    network['b2'] = np.zeros(2)  


    network['W3'] = np.array([[0.5, 0.1], [0.1, 0.2], [0.3, 0.4]])
    network['b3'] = np.zeros(2) 

    return network

#================================================================================================================

def forward(network, x):

    W1, b1 = network['W1'], network['b1']
    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)
    z_1 = relu(a1)
    
    z1 = np.insert(z1, 0, 1)  
    W2, b2 = network['W2'], network['b2']
    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)
    z_2 = relu(a2)

    z_2 = np.insert(z2, 0, 1)
    z2 = np.insert(z2, 0, 1) 
    W3, b3 = network['W3'], network['b3']
    a3 = np.dot(z2, W3) + b3
    output = a3

    return output

#====================================================================================================================

network = init_network()

#====================================================================================================================

x_input = np.array([1, 1, 0.5])  
#                      @   @  <<== 이거 두 개 input 
#====================================================================================================================

output = forward(network, x_input)

print("출력값은요:", output)
